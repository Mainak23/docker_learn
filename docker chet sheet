FROM rockylinux:9

RUN dnf install -y python3 && dnf clean all

WORKDIR /app
COPY index.html .

EXPOSE 8000
CMD ["python3", "-m", "http.server", "8000","--bind", "0.0.0.0"]

case 2
FROM rockylinux:9

RUN dnf install -y python3 && dnf clean all

WORKDIR /app
COPY test_folder/font_end .-------->inside docker copy everything inside font_end not font_end folder

EXPOSE 8000
CMD ["bash", "-c", "cd html_tag && python3 -m http.server 8000 --bind 0.0.0.0"]



1. Container lifecycle
Image â†’ Created â†’ Running â†’ Paused â†’ Exited â†’ Removed
Image = immutable blueprint
Container = running process + writable layer
PID 1 controls container life
If PID 1 exits â†’ container stops
run = create + start
exec = enter existing container


Containers need:
Read-only image layers
One writable layer
Zero copying
Fast startup
OverlayFS gives a union filesystem.

| Action          | Result               |
| --------------- | -------------------- |
| `podman run`    | NEW container        |
| `podman start`  | Existing container   |
| `podman rm`     | Container destroyed  |
| `podman commit` | Snapshot â†’ new image |
| `podman volume` | Persistent data      |


image comands
podman history my1stimage
podman inspect my1stimage


cointainer commandsd
podman ps
podman ps -a
podman run -it  e14d8cf0c63b (interactive)

volume commands


Build comand
podman build . -t myfirstimage


run comand
podman run -it   -p 8080:8000   b351a8ce3ab6 --------------> 8080 is host post where podman transfer it trafics from 8000 (inside podman port)
podman run -it e14d8cf0c63b bash -c "cd font_end && exec bash"

"""
Why exec bash matters
Replaces subshell
Keeps session alive
Correct PID 1 behavior
"""


path 

FROM rockylinux:9

#RUN dnf install -y python3 && dnf clean all

#WORKDIR /app --->not createing 
COPY test_folder .

EXPOSE 8000

podman run -it 513bfbbac171
[root@54e773483ab7 /]# ls
afs  bin  dev  etc  font_end  home  lib  lib64	lost+found  main.py  media  mnt  opt  proc  root  run  sbin  srv  sys  tmp  usr  var ----> find out file inside test folder not test folder

case 2
FROM rockylinux:9

#RUN dnf install -y python3 && dnf clean all

WORKDIR /app
COPY test_folder .

EXPOSE 8000
CMD ["bash", "-c", "cd font_end && python3 -m http.server 8000 --bind 0.0.0.0"]


Key rule:
Each comma-separated item = one argv element
No shell parsing happens unless you explicitly start a shell

Volume in podman 

Why volumes exist (first principles)
A container is ephemeral.
Container writable layer = temporary
podman rm â†’ all container data is gone
Image layers = read-only
So the problem is:
Where do we keep data that must survive container restarts, upgrades, crashes?
Answer: Volumes (or bind mounts).

Without volume (default behavior)

Image (read-only layers)
â†“
Container writable layer (OverlayFS upperdir)

If your app writes to /data:
Data lives in containerâ€™s writable layer
Stored in OverlayFS upperdir
When container is removed â†’ data is deleted

OverlayFS
OverlayFS is a Linux kernel filesystem, not a container feature.
Its job:
Merge multiple directories into one virtual filesystem

| Term     | Meaning                            |
| -------- | ---------------------------------- |
| lowerdir | One or more read-only directories  |
| upperdir | Writable directory                 |
| workdir  | Scratch space (required by kernel) |
| merged   | What processes see                 |


ML workloads do:
Large sequential reads (datasets, checkpoints)
Massive small writes (logs, temp files, tensor caches)
Frequent metadata ops (stat, open, close)


How Podman uses OverlayFS
Podman itself does not implement OverlayFS.
Podman only:
Prepares directories
Asks the kernel to mount OverlayFS
Manages lifecycle

OverlayFS is optimized for:
Read-heavy, write-light
App binaries, not data pipelines

OverlayFS is fine for:
Python code
Binaries
Small config files

OverlayFS is bad for:
ML data
Databases
Logs
Anything stateful


With volume (what actually happens)
Example:
podman run -v myvol:/app/data myimage

This means:

Host volume (real filesystem)
        â†‘
      mounted
        â†‘
Container path /app/data

Important rule (this answers your question directly):
Data is NOT copied into the container.
The container sees the host data directly.

Can you open these files directly?
âŒ No
They are:
Binary
Page-based
Engine-version specific
Checksummed and encrypted internally

Where you SHOULD mount container storage (best practice)
âŒ Never use
/
/boot
tmpfs

âœ… Best locations
Location	When to use
/mnt/docker-data	External disk
/data/containers	Separate internal disk
/srv/containers	Server-standard layout

When you should NOT use containers for DBs
If:
Single server
One SQL Server instance
Stable schema
No frequent redeployments
No CI/CD
Bare-metal performance matters

When containerized DB makes sense for you
Use Podman/Docker if:
You want clean rollback
You want staging/prod parity
You deploy frequently
You plan Kubernetes later
You want infra discipline
Donâ€™t use it if:
One DB
Rare changes
Performance is king
No automation


VolumeÂ¶
create Create a new volume
exists Check if the given volume exists
export Exports volume to external tar
import Import tarball contents into a podman volume
inspect Display detailed information on one or more volumes
ls List volumes
prune Remove all unused volumes
rm Remove one or more volumes

commands#################
podman volume create pgdata
/home/mainak/.local/share/containers/storage/volumes/pgdata/_data

sudo podman volume create pgdata----root full
/var/lib/containers/storage/volumes/pgdata/_data

Hidden directories in Linux start with a dot (.):
.local â† hidden

podman volume ls
podman volume inspect pgdata
podman ps -a --filter volume=pgdata ---which cointainer
podman volume rm pgdata
podman volume prune

all comands
| Command   | Description                  | Example                                  |
| --------- | ---------------------------- | ---------------------------------------- |
| `create`  | Create a new volume          | `podman volume create myvol`             |
| `exists`  | Check if a volume exists     | `podman volume exists myvol`             |
| `export`  | Export volume to tarball     | `podman volume export myvol > myvol.tar` |
| `import`  | Import tarball into a volume | `podman volume import myvol myvol.tar`   |
| `inspect` | Show detailed info of volume | `podman volume inspect myvol`            |
| `ls`      | List all volumes             | `podman volume ls`                       |
| `mount`   | Mount a volume filesystem    | `podman volume mount myvol`              |
| `prune`   | Remove all unused volumes    | `podman volume prune`                    |
| `reload`  | Reload volumes from plugins  | `podman volume reload`                   |
| `rm`      | Remove one or more volumes   | `podman volume rm myvol`                 |
| `unmount` | Unmount a volume filesystem  | `podman volume unmount myvol`            |


1ï¸âƒ£ Remove a specific volume
podman volume rm myvol
If it fails with â€œvolume is being usedâ€, it means a container still references it.
2ï¸âƒ£ Find which container is using a volume
podman ps -a --filter volume=myvol
Then remove that container:
podman rm -f <container_id>
Retry volume removal.
3ï¸âƒ£ Remove all unused (dangling) volumes (safe)
podman volume prune

export
podman stop quirky_gates
podman volume export pgdata > pgdata.tar (~/ : /home/user/ if not specifieds)
ls -lh pgdata.tar
tar tf pgdata.tar | head

import
podman volume create myvol
podman volume import myvol new.tar
podman run -d \
  --name some-postgres \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -v myvol:/var/lib/postgresql/data:Z \
  -p 5432:5432 \
  postgres




Why Podman forbids custom paths
Volumes must be portable
Podman must manage SELinux labels
Arbitrary paths = security + consistency problems

Important warning (donâ€™t skip)
Import replaces existing volume data
Stop containers using the volume before importing

4ï¸âƒ£ Why _data?
Podman/Docker keep metadata in the volume directory.
Your actual files are always inside _data/.

confirm
podman volume inspect pgdata

podman run -d \
  --name some-postgres \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -v pgdata:/var/lib/postgresql/data:Z \
  -p 5432:5432 \
  postgres





1ï¸âƒ£ What exactly is happening with pgdata:/var/lib/postgresql/data
-v pgdata:/var/lib/postgresql/data

Left side â†’ Host
pgdata = Podman named volume

Physically lives at:
~/.local/share/containers/storage/volumes/pgdata/_data


Right side â†’ Container
/var/lib/postgresql/data = PostgreSQLâ€™s data directory

Postgres must write here (WAL, tables, indexes)
ğŸ” Result:

Anything Postgres writes inside the container goes into the host volume.

Delete container â†’ data survives
Delete volume â†’ data is gone

#######INSPECTION##############
podman inspect -f '{{.ImageName}} {{.Image}}' f51892489929
podman ps -a --format "table {{.ID}}\t{{.Names}}\t{{.Image}}\t{{.Status}}"
podman system reset -f

###################################

podman run -d -e POSTGRES_PASSWORD=mysecretpassword -p 5432:5432 b5caf683a8bb (Image id)
podman exec -it quirky_gates psql -U postgres

postgres=#
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    name TEXT NOT NULL,
    email TEXT UNIQUE NOT NULL,
    created_at TIMESTAMP DEFAULT NOW()
);

INSERT INTO users (name, email)
VALUES
  ('Alice', 'alice@example.com'),
  ('Bob', 'bob@example.com');

SELECT * FROM users;

 id | name  |       email        |     created_at
----+-------+--------------------+---------------------
  1 | Alice | alice@example.com  | 2025-...
  2 | Bob   | bob@example.com    | 2025-...

#use one volume by multiple cointainer
Good for backups, analytics, migrations.

podman volume create pgdata

Primary Postgres (read-write)
podman run -d \
  --name pg-main \
  -e POSTGRES_PASSWORD=secret \
  -v pgdata:/var/lib/postgresql/data:Z \
  -p 5432:5432 \
  postgres:14

Secondary container (read-only)
podman run --rm -it \
  --name pg-tools \
  -v pgdata:/var/lib/postgresql/data:ro,Z \
  postgres:14 \
  bash



podman run -d \
  --name postgres14-mainak \
  -e POSTGRES_PASSWORD=mysecretpassword \
  -v pgdata:/var/lib/postgresql/data:Z \
  -p 5432:5432 \
  postgres:14



1ï¸âƒ£ Requirement on host
You must have psql client installed on your host.
Check:
psql --version

If not installed (Ubuntu/Debian):
sudo apt install postgresql-client

2ï¸âƒ£ Connect from host to the containerized Postgres
psql -h localhost -p 5432 -U postgres

postgres=#
SELECT * FROM users;

PGPASSWORD=mysecretpassword \
psql -h localhost -p 5432 -U postgres -d postgres -c "SELECT * FROM users;"

psql (host)
   â†“ localhost:5432
Podman port forward
   â†“ container:5432
Postgres server

____________________________
~/ : /home/mainak/
___________________________

Golden rules (lock these in)
Anonymous volumes = dangerous for databases
Always name your volumes
Always pin Postgres versions
Container deletion â‰  volume deletion
Postgres will silently ignore incompatible data dirs

podman rm -f $(podman ps -aq)
podman rmi -f $(podman images -aq)


########
network
#########
network command manages networks for Podman

Podman has two network backends:
Netavark (new) and CNI (old).
Netavark is the default from Podman 4.0.
CNI is deprecated and will be removed in Podman 5.0.
Network CLI commands stay the same, but
Network config files are different, so networks must be recreated if you switch backends.
Backend is set in containers.conf.

Podman â‰¤3.x â†’ CNI
Podman 4.x+ â†’ Netavark
Podman 5.0 â†’ CNI gone

Production rule (write this down)
Never switch network backends on a running system without recreating networks and containers.

Ignoring this causes:
Broken DNS
Containers not talking
Silent failures


Check current backend with:
podman --version
podman info --format '{{.Host.NetworkBackend}}'
If you see error
3.x â†’ this error is expected
4.x+ â†’ system packages may be mismatched

Podman 3.x (CNI only)
There is no Netavark in Podman 3.x.
So your backend is CNI by definition.
Confirm by checking CNI config:
ls ~/.config/cni/net.d/
----> 87-podman.conflist  cni.lock

What is 87-podman.conflist (important)
This file defines:

Bridge network
Subnet (e.g. 10.88.0.0/16)
Gateway
IPAM rules
Firewall + port mapping plugins
It is the default Podman network.

| Situation                      | Result              |
| ------------------------------ | ------------------- |
| You upgrade to Podman 4/5      | CNI ignored         |
| Containers rely on old network | They fail           |
| DNS resolution breaks          | Silent errors       |
| You donâ€™t recreate networks    | Debugging nightmare |

CNI configs â‰  Netavark configs. Same CLI, different engine.

If you upgrade from Podman 3 â†’ 4:
Existing CNI networks WILL NOT work
You must recreate networks
Containers depending on old networks will fail

CNI and Netavark solve similar-looking problems but are built for different worlds.

CNI = cluster networking (Kubernetes)
Netavark = local container networking (Podman)

Conceptual difference (WHY they exist)
CNI (Container Network Interface)

Goal:
â€œWhen a container (pod) starts, tell the system how to connect it to the cluster network.â€

Key idea:
CNI is a specification, not a tool
Kubernetes calls CNI plugins

Plugins decide:
IP assignment
Routing
Firewall rules

CNI assumes:
Many nodes
Flat network
No NAT between pods
Scale first, simplicity second

Netavark
Goal:
â€œGive local containers working networking with minimal overhead.â€

Key idea:
Netavark is a single-purpose engine
Written specifically for Podman
Opinionated and simple

Netavark assumes:
Single machine
Containers come and go fast
NAT is acceptable
Developer/ops convenience matters

| Aspect            | CNI (K8s)           | Netavark     |
| ----------------- | ------------------- | ------------ |
| Pod-to-pod        | Direct IP           | Often NAT    |
| Cross-node        | Required            | Not needed   |
| Load balancing    | Service abstraction | Port mapping |
| Performance focus | Scale               | Simplicity   |

Failure model (production insight)
CNI failures:
Pod stuck in ContainerCreating
Node-specific
Hard to debug
Often invisible at first

Netavark failures:
Container wonâ€™t start
Local and obvious
Easy to reproduce

NAT 
NAT (Network Address Translation) is:
A technique where a router rewrites IP addresses (and ports) so many private machines can share one public IP.

Problem:
IPv4 has limited addresses
Private networks use non-routable IPs:
10.x.x.x
172.16â€“31.x.x
192.168.x.x

These cannot travel on the internet.

Solution:
â¡ï¸ NAT sits at the boundary and translates them.

Mental model (lock this in)
NAT differentiates machines using PORTS.
Kubernetes differentiates pods using IPs.


They are differentiated by PORT NUMBERS, not just IP addresses.
IP + port together uniquely identify a connection.

Step 1ï¸âƒ£ What actually identifies a connection
A network connection is identified by this 5-tuple:
(Source IP, Source Port, Destination IP, Destination Port, Protocol)

Example:
(192.168.1.10, 43210, 8.8.8.8, 53, UDP)

Step 2ï¸âƒ£ What NAT really does (important correction)
NAT does NOT only change the IP.
It usually does PAT (Port Address Translation).

So it changes:
Source IP
Source Port

This is why thousands of machines can share one IP.

Step 3ï¸âƒ£ Concrete example (two pods, same public IP)

Assume two pods:

Pod	Private IP	Source Port
Pod A	10.88.0.2	40001
Pod B	10.88.0.3	40002

Both access:

8.8.8.8:53

Before NAT
10.88.0.2:40001 â†’ 8.8.8.8:53
10.88.0.3:40002 â†’ 8.8.8.8:53

After NAT (same public IP)
203.0.113.5:55001 â†’ 8.8.8.8:53
203.0.113.5:55002 â†’ 8.8.8.8:53


NAT table:
203.0.113.5:55001 â†” 10.88.0.2:40001
203.0.113.5:55002 â†” 10.88.0.3:40002


When replies come back:
Port 55001 â†’ Pod A
Port 55002 â†’ Pod B

Step 4ï¸âƒ£ Why ports are enough

TCP has 65,535 ports
UDP has 65,535 ports

NAT can reuse ports across different destinations
So a single IP can support millions of concurrent connections.

Step 5ï¸âƒ£ Incoming traffic (important limitation)

Hereâ€™s the catch:
âŒ Incoming traffic cannot magically know which pod to reach.

Thatâ€™s why we need:
DNAT / Port Forwarding
PublicIP:80 â†’ PodA:8080


Choose the most isolated mode that still works for your app.

| Mode         | Isolation | NAT | Performance | Use case        |
| ------------ | --------- | --- | ----------- | --------------- |
| bridge       | High      | Yes | Medium      | Default         |
| host         | None      | No  | Very high   | Monitoring      |
| none         | Total     | No  | N/A         | Secure jobs     |
| user network | High      | Yes | Medium      | Microservices   |
| slirp4netns  | Medium    | Yes | Low         | Rootless        |
| pasta        | Medium    | Yes | High        | Rootless (best) |

Letâ€™s explain only the PORT part, nothing else.
0.0.0.0:5432 -> 5432/tcp
Right side: 5432/tcp
Port inside the container

PostgreSQL always listens on TCP 5432
This is the databaseâ€™s internal socket

Left side: 0.0.0.0:5432
Port on your host machine
0.0.0.0 = all network interfaces
localhost (127.0.0.1)
LAN IP

any other attached interface
Any connection hitting host:5432 is forwarded

The arrow ->
NAT port forwarding

Podman maps:
host:5432  â†’  container:5432


Compose

| Concept   | What it does                                           | When you use it                                          |
| --------- | ------------------------------------------------------ | -------------------------------------------------------- |
| `build`   | Creates an **image** of your app (e.g., Flask API)     | When you have custom code                                |
| `compose` | Launches **containers**, networks them, sets env/ports | When you want multi-container setup or service discovery |

flask-api/
  Dockerfile
  requirements.txt 
  app.py
compose.yml

proces
podman build -t myflaskapi .
podman-compose up -d

run
podman exec -it client sh
curl http://api:5000

One-line takeaway
run is fine for one container, Compose is essential for multi-container apps with shared networks, DNS, and volumes.
Dockerfile / Podmanfile = image definition only

Dockerfile defines:
Base image
Files to copy
Dependencies (pip install, apt install)
Environment variables
Default command (CMD)
Exposed ports (optional, for documentation)
It does not run containers or connect them to networks.

2ï¸âƒ£ Networking is runtime configuration
Networks exist only when containers are running.
Compose / podman run / Kubernetes YAML handles:
Which containers are on which network
Port mapping (host:container)
DNS resolution between containers
Isolation/security

| Build (Dockerfile) | Runtime (Compose) |
| ------------------ | ----------------- |
| Static             | Dynamic           |
| No IP              | IP assigned       |
| No DNS             | Built-in DNS      |
| No ports open      | Ports mapped      |
| No neighbors       | Multi-container   |


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Source Code â”‚
â”‚  (Flask app, etc.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dockerfile       â”‚
â”‚  - FROM            â”‚
â”‚  - COPY            â”‚
â”‚  - RUN pip install â”‚
â”‚  - CMD             â”‚
â”‚  - EXPOSE 5000     â”‚  â† documentation only
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚  podman build
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     IMAGE          â”‚
â”‚  myflaskapi:latest â”‚
â”‚  (static artifact) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Your Source Code â”‚
â”‚  (Flask app, etc.) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dockerfile       â”‚
â”‚  - FROM            â”‚
â”‚  - COPY            â”‚
â”‚  - RUN pip install â”‚
â”‚  - CMD             â”‚
â”‚  - EXPOSE 5000     â”‚  â† documentation only
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚  podman build
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     IMAGE          â”‚
â”‚  myflaskapi:latest â”‚
â”‚  (static artifact) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


Focus on:
How pod IPs are assigned
How pods talk across nodes
How services route traffic
How DNS works (CoreDNS)


#####################3
podman build --help

http://localhost:8080/

Full Podman reset (containers + images + networks + cache)
podman system reset -f
####################

Multi-stage 
Multi-stage builds are mandatory in prod
Single-stage images = amateur
Smaller images = faster deploy + safer
If you need bash in runtime, rethink design














